---
title: "Group 1"
author: "Joseph Lynch"
date: "6/13/2020"
output: html_document
---

```{r}
####Problem 1######
library(readxl)
Toyota <- read_excel("C:/Users/Administrator/Documents/ToyotaCorolla.xlsx")

spec = c(train = .5, test = .2, validate = .3)

g = sample(cut(
  seq(nrow(Toyota)), 
  nrow(Toyota)*cumsum(c(0,spec)),
  labels = names(spec)
))

res = split(Toyota, g)

train <- res$train
valid <- res$validate
test <- res$test

library(rpart)
library(rpart.plot)
#a.

reg.tree <- rpart(Price ~ Age_08_04 + KM + Fuel_Type + HP + Automatic + Doors + Quarterly_Tax + Mfr_Guarantee + Guarantee_Period + Airco + Automatic_airco + CD_Player + Powered_Windows + Sport_Model + Tow_Bar, 
                  method="anova", data = train,
                  minbucket = 1, maxdepth = 30, cp = 0.001, xval = 5)
prp(reg.tree)

#### i.

print(reg.tree$variable.importance)


#According to the summary, the most important variables are Age_08_04, KM and
#Automatic_airco

#### ii.

train.pred <- predict(reg.tree, train[,c(4,7,8,9,12,14,17,19,21,25,26,28,30,34,39)])
valid.pred <- predict(reg.tree, valid[,c(4,7,8,9,12,14,17,19,21,25,26,28,30,34,39)])
test.pred <- predict(reg.tree, test[,c(4,7,8,9,12,14,17,19,21,25,26,28,30,34,39)])

train.RMSE <- sqrt(sum((train[, 3] - as.array(train.pred))^2)/nrow(as.array(train.pred)))
valid.RMSE <- sqrt(sum((valid[, 3] - as.array(valid.pred))^2)/nrow(as.array(valid.pred)))
test.RMSE <- sqrt(sum((valid[, 3] - as.array(test.pred))^2)/nrow(as.array(test.pred)))

train.RMSE
valid.RMSE
test.RMSE
par(mfrow = c(1, 3))
boxplot(train.pred, main = "train.pred")
boxplot(valid.pred, main = "valid.pred")
boxplot(test.pred, main = "test.pred")

par(mfrow = c(1, 1))


#The validation set has a RMSE of 1405.103. The training set has a #RMSE of 914.8486. The validation set's RMSE is higher than 
#the training possibly due to overfitting. The test set has a #higher RMSE than either of the other two because it is using #actual data in comparison to the validation and training sets #which tend to overfit to the data. 



#### iv.


BestPruned <- prune(reg.tree,
                   cp = reg.tree$cptable[which.min(reg.tree$cptable[,"xerror"]),"CP"])
prp(BestPruned)
valid.pred <- predict(BestPruned, valid[,c(4,7,8,9,12,14,17,19,21,25,26,28,30,34,39)])
valid.RMSE <- sqrt(sum((valid[, 3] - as.array(valid.pred))^2)/nrow(as.array(valid.pred)))
valid.RMSE


#The full tree will have worse predictive performance for the #validation set when compared with the best pruned tree because the #best pruned tree has better generalized prediction
#while the full tree will be overfitted which precisely classifies #all the training data.


#b.

summary(Toyota$Price)
Toyota$Binned_Price <- cut(Toyota$Price, breaks = seq(4300, 32500, by = 1410))
train.index <- sample(c(1:dim(Toyota)[1]), dim(Toyota)[1]*0.6)
training2 <- Toyota[train.index, ]
validating2 <- Toyota[-train.index, ]
class.tree <- rpart(Binned_Price ~ Age_08_04 + KM + Fuel_Type + HP + Automatic + Doors + Quarterly_Tax + Mfr_Guarantee + Guarantee_Period + Airco + Automatic_airco + CD_Player + Powered_Windows + Sport_Model + Tow_Bar, 
                    method="anova", data = training2, minbucket = 1)
prp(class.tree, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10)


#### i.

#The trees look distinct.  The CT looks smaller than the RT and less complex


#### ii.

new_data <- data.frame(Age_08_04 = 77, KM = 117000,Fuel_Type = "Petrol",HP = 110,Automatic = 0,Doors = 5, Quarterly_Tax = 100,Mfr_Guarantee = 0,Guarantee_Period = 3,Airco = 1,Automatic_airco = 0,CD_Player = 0,Powered_Windows = 0,Sport_Model = 0,Tow_Bar = 1)
new.reg.pred <- predict(reg.tree, new_data)
new.class.pred <- predict(class.tree, new_data)
new.reg.pred
new.class.pred * 1410 + 4300


#### iii.

valid2.pred <- predict(class.tree, validating2[,c(4,7,8,9,12,14,17,19,21,25,26,28,30,34,39)])
valid2.pred <- valid2.pred * 1410 + 4300
valid2.RMSE <- sqrt(sum((validating2[, 3] - as.array(valid2.pred))^2)/nrow(as.array(valid2.pred)))
valid2.RMSE



#The difference between CT and RT is are more than 1000. CT's rule set is simpler than RT. CT's validation set has a higher RMSE.
#RT has a higher accuracy than CT because we binned CT whereas the actual numbers were used  for RT. 



####Problem 2######


library(readxl)
Banks <- read_excel("C:/Users/Administrator/Documents/Banks.xlsx")

TotLns.Lses.Assets<- Banks$`TotLns&Lses/Assets`
TotExp.Assets <- Banks$`TotExp/Assets`

logit.reg <- glm(Banks$`Financial Condition` ~ TotExp.Assets + TotLns.Lses.Assets, data = Banks, family = "binomial")
summary(logit.reg)


#a.

#### i.

#Logit: Logit= -14.188 + 79.964 x (TotExp/Assets) + 9.173 x (TotLns&Lses/Assets)

####ii.

#Odds Format: Odds= e^(-14.188 + 79.964 x TotExp/Assets + 9.173 x TotLns&Lses/Assets)

####iii.

#Probability: Probability= 1 / (1 + e^(-14.188 + 79.964 x TotExp/Assets + 9.173 x TotLns&Lses/Assets))



# New bank: TotLns.Lses.Assets = 0.6, TotExp.Assets = 0.11.
new_bank <- data.frame(TotLns.Lses.Assets = 0.6, TotExp.Assets = 0.11)


#1 Logit - 0.11184


logit <- -14.188 + 79.964 * 0.11 +  9.173 * 0.6
logit


#2 Odds - 1.118334


odds <- exp(logit)
odds


#3 Probability  - 0.4720691


probability <- 1 / (1 + odds)
probability


#4 The classification of the bank : Not weak.

pred <- predict(logit.reg,new_bank)
pred

#c. 
#If the cutoff value is 0.5 based on odds, then the odds are equal to 1, and the  logit is zero.

#odds = p/1-p = .5/(1-.5) = 1
#logit = log(odds) = log(1) = 0 


#d
#TotLns.Lses.Assets has a positive coefficient, meaning as TotLns.Lses.Assets increases, the odds of a bank classifiying as weak also increase.
#A one unit increase of TotLns&Lses/Asset, holding constant everything else, results in an increase in the odds that bank is weak by e^(8.731).

#e We should decrease the cutoff value in order to decrease the chances misclassifying banks in weak conditions as strong


```{r}

#####Problem 3#####
library(readxl)
SysAdmins <- read_excel("C:/Users/Administrator/Documents/System Administrators.xlsx")
str(SysAdmins)

library(ggplot2)

#a
Task <-as.factor(SysAdmins$`Completed task`)
library(car)
library(caret)
par(mar=c(6,6,6,6))
scatterplot(SysAdmins$Experience ~ SysAdmins$Training | SysAdmins$`Completed task`, data = SysAdmins,  grid = TRUE, frame = TRUE)

#Experience appears to be a good predictor to classify whether the task was completed.


#b
logit.reg <- glm(Task ~ SysAdmins$Experience+SysAdmins$Training, data = SysAdmins, family = "binomial")
summary(logit.reg)
Prediction <- predict(logit.reg, SysAdmins)
confusionMatrix(as.factor(ifelse(Prediction > 0.5, "Yes", "No")), Task)

# 6/15 = 40%

#c. To decrease the amount of programmers who are misclassified, the cutoff value should be decreased

#d. How much experience must be accumulated by a programmer with 4 years of training before his or her estimated probability of completing the task exceeds 50%?

#Prediction=.5

#Prediction = -10.9813 + 1.1269 *Experience + .1805 * Training
#Prediction = -10.9813 + 1.1269 * Experience + .722
#Prediction+10.9813=1.1269*Experience+.722
#.5+10.2593=1.1269*Experience
# 10.7593=1.1269*Experience
#Experience=9.54769, so more than 9.54769 years experience to exceed probability of completing the task over 50%


```{r}
